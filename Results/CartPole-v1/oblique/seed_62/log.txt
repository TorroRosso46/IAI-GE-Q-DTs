__name__: __main__
__doc__: None
__package__: None
__loader__: <_frozen_importlib_external.SourceFileLoader object at 0x000001F0B6DC1F70>
__spec__: None
__annotations__: {}
__builtins__: <module 'builtins' (built-in)>
__file__: C:\Users\rosse\Documents\Informatik\RL Git\IAI-GE-Q-DTs\test_evolution.py
__cached__: None
os: <module 'os' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\os.py'>
gym: <module 'gym' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\site-packages\\gym\\__init__.py'>
string: <module 'string' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\string.py'>
datetime: <module 'datetime' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\datetime.py'>
argparse: <module 'argparse' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\argparse.py'>
np: <module 'numpy' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\site-packages\\numpy\\__init__.py'>
random: <module 'numpy.random' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\site-packages\\numpy\\random\\__init__.py'>
plt: <module 'matplotlib.pyplot' from 'C:\\Users\\rosse\\anaconda3\\envs\\ge\\lib\\site-packages\\matplotlib\\pyplot.py'>
DecisionTree: <class 'decision_tree.DecisionTree'>
Leaf: <class 'decision_tree.Leaf'>
grammatical_evolution: <function grammatical_evolution at 0x000001F0C172C550>
GETranslator: <class 'ge_translator.GETranslator'>
string_to_dict: <function string_to_dict at 0x000001F0B7855790>
parser: ArgumentParser(prog='test_evolution.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)
date: 2022-03-02_22-23-46
logdir: logs/gym/2022-03-02_22-23-46_yxvbhfqk
logfile: logs/gym/2022-03-02_22-23-46_yxvbhfqk\log.txt
fitfile: logs/gym/2022-03-02_22-23-46_yxvbhfqk\fitness.tsv
pltfile_jpg: logs/gym/2022-03-02_22-23-46_yxvbhfqk\fitness.jpg
pltfile_pdf: logs/gym/2022-03-02_22-23-46_yxvbhfqk\fitness.pdf
args: Namespace(grammar='oblique', seed=62, environment_name='CartPole-v1', n_actions=4, learning_rate='0.001', df=0.9, eps=0.05, input_space=4, episodes=10, episode_len=1000, population_size=200, generations=50, cxp=0.0, mp=1.0, mutation={'function': 'tools.mutUniformInt', 'low': 0, 'up': 4000, 'indpb': 0.1}, genotype_len=100, low=-1.0, up=1.0, decay=0.99, with_bias=True, types='#-48,48,5,10;-50,50,5,10;-418,418,5,1000;-836,836,5,1000', randInit=True)
input_space_size: 4
lr: 0.001
CLeaf: <class '__main__.CLeaf'>
EpsilonDecayLeaf: <class '__main__.EpsilonDecayLeaf'>
ORTHOGONAL_GRAMMAR: {'dt': ['<if>'], 'if': ['if <condition>:{<action>}else:{<action>}'], 'condition': ['_in_0<comp_op><const_type_0>', '_in_1<comp_op><const_type_1>', '_in_2<comp_op><const_type_2>', '_in_3<comp_op><const_type_3>'], 'action': ['out=_leaf;leaf="_leaf"', '<if>'], 'comp_op': [' < ', ' > ']}
OBLIQUE_GRAMMAR: {'dt': ['<if>'], 'if': ['if <condition>:{<action>}else:{<action>}'], 'action': ['out=_leaf;leaf="_leaf"', '<if>'], 'const': ['-1.0', '-0.999', '-0.998', '-0.997', '-0.996', '-0.995', '-0.994', '-0.993', '-0.992', '-0.991', '-0.99', '-0.989', '-0.988', '-0.987', '-0.986', '-0.985', '-0.984', '-0.983', '-0.982', '-0.981', '-0.98', '-0.979', '-0.978', '-0.977', '-0.976', '-0.975', '-0.974', '-0.973', '-0.972', '-0.971', '-0.97', '-0.969', '-0.968', '-0.967', '-0.966', '-0.965', '-0.964', '-0.963', '-0.962', '-0.961', '-0.96', '-0.959', '-0.958', '-0.957', '-0.956', '-0.955', '-0.954', '-0.953', '-0.952', '-0.951', '-0.95', '-0.949', '-0.948', '-0.947', '-0.946', '-0.945', '-0.944', '-0.943', '-0.942', '-0.941', '-0.94', '-0.939', '-0.938', '-0.937', '-0.936', '-0.935', '-0.934', '-0.933', '-0.932', '-0.931', '-0.93', '-0.929', '-0.928', '-0.927', '-0.926', '-0.925', '-0.924', '-0.923', '-0.922', '-0.921', '-0.92', '-0.919', '-0.918', '-0.917', '-0.916', '-0.915', '-0.914', '-0.913', '-0.912', '-0.911', '-0.91', '-0.909', '-0.908', '-0.907', '-0.906', '-0.905', '-0.904', '-0.903', '-0.902', '-0.901', '-0.9', '-0.899', '-0.898', '-0.897', '-0.896', '-0.895', '-0.894', '-0.893', '-0.892', '-0.891', '-0.89', '-0.889', '-0.888', '-0.887', '-0.886', '-0.885', '-0.884', '-0.883', '-0.882', '-0.881', '-0.88', '-0.879', '-0.878', '-0.877', '-0.876', '-0.875', '-0.874', '-0.873', '-0.872', '-0.871', '-0.87', '-0.869', '-0.868', '-0.867', '-0.866', '-0.865', '-0.864', '-0.863', '-0.862', '-0.861', '-0.86', '-0.859', '-0.858', '-0.857', '-0.856', '-0.855', '-0.854', '-0.853', '-0.852', '-0.851', '-0.85', '-0.849', '-0.848', '-0.847', '-0.846', '-0.845', '-0.844', '-0.843', '-0.842', '-0.841', '-0.84', '-0.839', '-0.838', '-0.837', '-0.836', '-0.835', '-0.834', '-0.833', '-0.832', '-0.831', '-0.83', '-0.829', '-0.828', '-0.827', '-0.826', '-0.825', '-0.824', '-0.823', '-0.822', '-0.821', '-0.82', '-0.819', '-0.818', '-0.817', '-0.816', '-0.815', '-0.814', '-0.813', '-0.812', '-0.811', '-0.81', '-0.809', '-0.808', '-0.807', '-0.806', '-0.805', '-0.804', '-0.803', '-0.802', '-0.801', '-0.8', '-0.799', '-0.798', '-0.797', '-0.796', '-0.795', '-0.794', '-0.793', '-0.792', '-0.791', '-0.79', '-0.789', '-0.788', '-0.787', '-0.786', '-0.785', '-0.784', '-0.783', '-0.782', '-0.781', '-0.78', '-0.779', '-0.778', '-0.777', '-0.776', '-0.775', '-0.774', '-0.773', '-0.772', '-0.771', '-0.77', '-0.769', '-0.768', '-0.767', '-0.766', '-0.765', '-0.764', '-0.763', '-0.762', '-0.761', '-0.76', '-0.759', '-0.758', '-0.757', '-0.756', '-0.755', '-0.754', '-0.753', '-0.752', '-0.751', '-0.75', '-0.749', '-0.748', '-0.747', '-0.746', '-0.745', '-0.744', '-0.743', '-0.742', '-0.741', '-0.74', '-0.739', '-0.738', '-0.737', '-0.736', '-0.735', '-0.734', '-0.733', '-0.732', '-0.731', '-0.73', '-0.729', '-0.728', '-0.727', '-0.726', '-0.725', '-0.724', '-0.723', '-0.722', '-0.721', '-0.72', '-0.719', '-0.718', '-0.717', '-0.716', '-0.715', '-0.714', '-0.713', '-0.712', '-0.711', '-0.71', '-0.709', '-0.708', '-0.707', '-0.706', '-0.705', '-0.704', '-0.703', '-0.702', '-0.701', '-0.7', '-0.699', '-0.698', '-0.697', '-0.696', '-0.695', '-0.694', '-0.693', '-0.692', '-0.691', '-0.69', '-0.689', '-0.688', '-0.687', '-0.686', '-0.685', '-0.684', '-0.683', '-0.682', '-0.681', '-0.68', '-0.679', '-0.678', '-0.677', '-0.676', '-0.675', '-0.674', '-0.673', '-0.672', '-0.671', '-0.67', '-0.669', '-0.668', '-0.667', '-0.666', '-0.665', '-0.664', '-0.663', '-0.662', '-0.661', '-0.66', '-0.659', '-0.658', '-0.657', '-0.656', '-0.655', '-0.654', '-0.653', '-0.652', '-0.651', '-0.65', '-0.649', '-0.648', '-0.647', '-0.646', '-0.645', '-0.644', '-0.643', '-0.642', '-0.641', '-0.64', '-0.639', '-0.638', '-0.637', '-0.636', '-0.635', '-0.634', '-0.633', '-0.632', '-0.631', '-0.63', '-0.629', '-0.628', '-0.627', '-0.626', '-0.625', '-0.624', '-0.623', '-0.622', '-0.621', '-0.62', '-0.619', '-0.618', '-0.617', '-0.616', '-0.615', '-0.614', '-0.613', '-0.612', '-0.611', '-0.61', '-0.609', '-0.608', '-0.607', '-0.606', '-0.605', '-0.604', '-0.603', '-0.602', '-0.601', '-0.6', '-0.599', '-0.598', '-0.597', '-0.596', '-0.595', '-0.594', '-0.593', '-0.592', '-0.591', '-0.59', '-0.589', '-0.588', '-0.587', '-0.586', '-0.585', '-0.584', '-0.583', '-0.582', '-0.581', '-0.58', '-0.579', '-0.578', '-0.577', '-0.576', '-0.575', '-0.574', '-0.573', '-0.572', '-0.571', '-0.57', '-0.569', '-0.568', '-0.567', '-0.566', '-0.565', '-0.564', '-0.563', '-0.562', '-0.561', '-0.56', '-0.559', '-0.558', '-0.557', '-0.556', '-0.555', '-0.554', '-0.553', '-0.552', '-0.551', '-0.55', '-0.549', '-0.548', '-0.547', '-0.546', '-0.545', '-0.544', '-0.543', '-0.542', '-0.541', '-0.54', '-0.539', '-0.538', '-0.537', '-0.536', '-0.535', '-0.534', '-0.533', '-0.532', '-0.531', '-0.53', '-0.529', '-0.528', '-0.527', '-0.526', '-0.525', '-0.524', '-0.523', '-0.522', '-0.521', '-0.52', '-0.519', '-0.518', '-0.517', '-0.516', '-0.515', '-0.514', '-0.513', '-0.512', '-0.511', '-0.51', '-0.509', '-0.508', '-0.507', '-0.506', '-0.505', '-0.504', '-0.503', '-0.502', '-0.501', '-0.5', '-0.499', '-0.498', '-0.497', '-0.496', '-0.495', '-0.494', '-0.493', '-0.492', '-0.491', '-0.49', '-0.489', '-0.488', '-0.487', '-0.486', '-0.485', '-0.484', '-0.483', '-0.482', '-0.481', '-0.48', '-0.479', '-0.478', '-0.477', '-0.476', '-0.475', '-0.474', '-0.473', '-0.472', '-0.471', '-0.47', '-0.469', '-0.468', '-0.467', '-0.466', '-0.465', '-0.464', '-0.463', '-0.462', '-0.461', '-0.46', '-0.459', '-0.458', '-0.457', '-0.456', '-0.455', '-0.454', '-0.453', '-0.452', '-0.451', '-0.45', '-0.449', '-0.448', '-0.447', '-0.446', '-0.445', '-0.444', '-0.443', '-0.442', '-0.441', '-0.44', '-0.439', '-0.438', '-0.437', '-0.436', '-0.435', '-0.434', '-0.433', '-0.432', '-0.431', '-0.43', '-0.429', '-0.428', '-0.427', '-0.426', '-0.425', '-0.424', '-0.423', '-0.422', '-0.421', '-0.42', '-0.419', '-0.418', '-0.417', '-0.416', '-0.415', '-0.414', '-0.413', '-0.412', '-0.411', '-0.41', '-0.409', '-0.408', '-0.407', '-0.406', '-0.405', '-0.404', '-0.403', '-0.402', '-0.401', '-0.4', '-0.399', '-0.398', '-0.397', '-0.396', '-0.395', '-0.394', '-0.393', '-0.392', '-0.391', '-0.39', '-0.389', '-0.388', '-0.387', '-0.386', '-0.385', '-0.384', '-0.383', '-0.382', '-0.381', '-0.38', '-0.379', '-0.378', '-0.377', '-0.376', '-0.375', '-0.374', '-0.373', '-0.372', '-0.371', '-0.37', '-0.369', '-0.368', '-0.367', '-0.366', '-0.365', '-0.364', '-0.363', '-0.362', '-0.361', '-0.36', '-0.359', '-0.358', '-0.357', '-0.356', '-0.355', '-0.354', '-0.353', '-0.352', '-0.351', '-0.35', '-0.349', '-0.348', '-0.347', '-0.346', '-0.345', '-0.344', '-0.343', '-0.342', '-0.341', '-0.34', '-0.339', '-0.338', '-0.337', '-0.336', '-0.335', '-0.334', '-0.333', '-0.332', '-0.331', '-0.33', '-0.329', '-0.328', '-0.327', '-0.326', '-0.325', '-0.324', '-0.323', '-0.322', '-0.321', '-0.32', '-0.319', '-0.318', '-0.317', '-0.316', '-0.315', '-0.314', '-0.313', '-0.312', '-0.311', '-0.31', '-0.309', '-0.308', '-0.307', '-0.306', '-0.305', '-0.304', '-0.303', '-0.302', '-0.301', '-0.3', '-0.299', '-0.298', '-0.297', '-0.296', '-0.295', '-0.294', '-0.293', '-0.292', '-0.291', '-0.29', '-0.289', '-0.288', '-0.287', '-0.286', '-0.285', '-0.284', '-0.283', '-0.282', '-0.281', '-0.28', '-0.279', '-0.278', '-0.277', '-0.276', '-0.275', '-0.274', '-0.273', '-0.272', '-0.271', '-0.27', '-0.269', '-0.268', '-0.267', '-0.266', '-0.265', '-0.264', '-0.263', '-0.262', '-0.261', '-0.26', '-0.259', '-0.258', '-0.257', '-0.256', '-0.255', '-0.254', '-0.253', '-0.252', '-0.251', '-0.25', '-0.249', '-0.248', '-0.247', '-0.246', '-0.245', '-0.244', '-0.243', '-0.242', '-0.241', '-0.24', '-0.239', '-0.238', '-0.237', '-0.236', '-0.235', '-0.234', '-0.233', '-0.232', '-0.231', '-0.23', '-0.229', '-0.228', '-0.227', '-0.226', '-0.225', '-0.224', '-0.223', '-0.222', '-0.221', '-0.22', '-0.219', '-0.218', '-0.217', '-0.216', '-0.215', '-0.214', '-0.213', '-0.212', '-0.211', '-0.21', '-0.209', '-0.208', '-0.207', '-0.206', '-0.205', '-0.204', '-0.203', '-0.202', '-0.201', '-0.2', '-0.199', '-0.198', '-0.197', '-0.196', '-0.195', '-0.194', '-0.193', '-0.192', '-0.191', '-0.19', '-0.189', '-0.188', '-0.187', '-0.186', '-0.185', '-0.184', '-0.183', '-0.182', '-0.181', '-0.18', '-0.179', '-0.178', '-0.177', '-0.176', '-0.175', '-0.174', '-0.173', '-0.172', '-0.171', '-0.17', '-0.169', '-0.168', '-0.167', '-0.166', '-0.165', '-0.164', '-0.163', '-0.162', '-0.161', '-0.16', '-0.159', '-0.158', '-0.157', '-0.156', '-0.155', '-0.154', '-0.153', '-0.152', '-0.151', '-0.15', '-0.149', '-0.148', '-0.147', '-0.146', '-0.145', '-0.144', '-0.143', '-0.142', '-0.141', '-0.14', '-0.139', '-0.138', '-0.137', '-0.136', '-0.135', '-0.134', '-0.133', '-0.132', '-0.131', '-0.13', '-0.129', '-0.128', '-0.127', '-0.126', '-0.125', '-0.124', '-0.123', '-0.122', '-0.121', '-0.12', '-0.119', '-0.118', '-0.117', '-0.116', '-0.115', '-0.114', '-0.113', '-0.112', '-0.111', '-0.11', '-0.109', '-0.108', '-0.107', '-0.106', '-0.105', '-0.104', '-0.103', '-0.102', '-0.101', '-0.1', '-0.099', '-0.098', '-0.097', '-0.096', '-0.095', '-0.094', '-0.093', '-0.092', '-0.091', '-0.09', '-0.089', '-0.088', '-0.087', '-0.086', '-0.085', '-0.084', '-0.083', '-0.082', '-0.081', '-0.08', '-0.079', '-0.078', '-0.077', '-0.076', '-0.075', '-0.074', '-0.073', '-0.072', '-0.071', '-0.07', '-0.069', '-0.068', '-0.067', '-0.066', '-0.065', '-0.064', '-0.063', '-0.062', '-0.061', '-0.06', '-0.059', '-0.058', '-0.057', '-0.056', '-0.055', '-0.054', '-0.053', '-0.052', '-0.051', '-0.05', '-0.049', '-0.048', '-0.047', '-0.046', '-0.045', '-0.044', '-0.043', '-0.042', '-0.041', '-0.04', '-0.039', '-0.038', '-0.037', '-0.036', '-0.035', '-0.034', '-0.033', '-0.032', '-0.031', '-0.03', '-0.029', '-0.028', '-0.027', '-0.026', '-0.025', '-0.024', '-0.023', '-0.022', '-0.021', '-0.02', '-0.019', '-0.018', '-0.017', '-0.016', '-0.015', '-0.014', '-0.013', '-0.012', '-0.011', '-0.01', '-0.009', '-0.008', '-0.007', '-0.006', '-0.005', '-0.004', '-0.003', '-0.002', '-0.001', '0.0', '0.001', '0.002', '0.003', '0.004', '0.005', '0.006', '0.007', '0.008', '0.009', '0.01', '0.011', '0.012', '0.013', '0.014', '0.015', '0.016', '0.017', '0.018', '0.019', '0.02', '0.021', '0.022', '0.023', '0.024', '0.025', '0.026', '0.027', '0.028', '0.029', '0.03', '0.031', '0.032', '0.033', '0.034', '0.035', '0.036', '0.037', '0.038', '0.039', '0.04', '0.041', '0.042', '0.043', '0.044', '0.045', '0.046', '0.047', '0.048', '0.049', '0.05', '0.051', '0.052', '0.053', '0.054', '0.055', '0.056', '0.057', '0.058', '0.059', '0.06', '0.061', '0.062', '0.063', '0.064', '0.065', '0.066', '0.067', '0.068', '0.069', '0.07', '0.071', '0.072', '0.073', '0.074', '0.075', '0.076', '0.077', '0.078', '0.079', '0.08', '0.081', '0.082', '0.083', '0.084', '0.085', '0.086', '0.087', '0.088', '0.089', '0.09', '0.091', '0.092', '0.093', '0.094', '0.095', '0.096', '0.097', '0.098', '0.099', '0.1', '0.101', '0.102', '0.103', '0.104', '0.105', '0.106', '0.107', '0.108', '0.109', '0.11', '0.111', '0.112', '0.113', '0.114', '0.115', '0.116', '0.117', '0.118', '0.119', '0.12', '0.121', '0.122', '0.123', '0.124', '0.125', '0.126', '0.127', '0.128', '0.129', '0.13', '0.131', '0.132', '0.133', '0.134', '0.135', '0.136', '0.137', '0.138', '0.139', '0.14', '0.141', '0.142', '0.143', '0.144', '0.145', '0.146', '0.147', '0.148', '0.149', '0.15', '0.151', '0.152', '0.153', '0.154', '0.155', '0.156', '0.157', '0.158', '0.159', '0.16', '0.161', '0.162', '0.163', '0.164', '0.165', '0.166', '0.167', '0.168', '0.169', '0.17', '0.171', '0.172', '0.173', '0.174', '0.175', '0.176', '0.177', '0.178', '0.179', '0.18', '0.181', '0.182', '0.183', '0.184', '0.185', '0.186', '0.187', '0.188', '0.189', '0.19', '0.191', '0.192', '0.193', '0.194', '0.195', '0.196', '0.197', '0.198', '0.199', '0.2', '0.201', '0.202', '0.203', '0.204', '0.205', '0.206', '0.207', '0.208', '0.209', '0.21', '0.211', '0.212', '0.213', '0.214', '0.215', '0.216', '0.217', '0.218', '0.219', '0.22', '0.221', '0.222', '0.223', '0.224', '0.225', '0.226', '0.227', '0.228', '0.229', '0.23', '0.231', '0.232', '0.233', '0.234', '0.235', '0.236', '0.237', '0.238', '0.239', '0.24', '0.241', '0.242', '0.243', '0.244', '0.245', '0.246', '0.247', '0.248', '0.249', '0.25', '0.251', '0.252', '0.253', '0.254', '0.255', '0.256', '0.257', '0.258', '0.259', '0.26', '0.261', '0.262', '0.263', '0.264', '0.265', '0.266', '0.267', '0.268', '0.269', '0.27', '0.271', '0.272', '0.273', '0.274', '0.275', '0.276', '0.277', '0.278', '0.279', '0.28', '0.281', '0.282', '0.283', '0.284', '0.285', '0.286', '0.287', '0.288', '0.289', '0.29', '0.291', '0.292', '0.293', '0.294', '0.295', '0.296', '0.297', '0.298', '0.299', '0.3', '0.301', '0.302', '0.303', '0.304', '0.305', '0.306', '0.307', '0.308', '0.309', '0.31', '0.311', '0.312', '0.313', '0.314', '0.315', '0.316', '0.317', '0.318', '0.319', '0.32', '0.321', '0.322', '0.323', '0.324', '0.325', '0.326', '0.327', '0.328', '0.329', '0.33', '0.331', '0.332', '0.333', '0.334', '0.335', '0.336', '0.337', '0.338', '0.339', '0.34', '0.341', '0.342', '0.343', '0.344', '0.345', '0.346', '0.347', '0.348', '0.349', '0.35', '0.351', '0.352', '0.353', '0.354', '0.355', '0.356', '0.357', '0.358', '0.359', '0.36', '0.361', '0.362', '0.363', '0.364', '0.365', '0.366', '0.367', '0.368', '0.369', '0.37', '0.371', '0.372', '0.373', '0.374', '0.375', '0.376', '0.377', '0.378', '0.379', '0.38', '0.381', '0.382', '0.383', '0.384', '0.385', '0.386', '0.387', '0.388', '0.389', '0.39', '0.391', '0.392', '0.393', '0.394', '0.395', '0.396', '0.397', '0.398', '0.399', '0.4', '0.401', '0.402', '0.403', '0.404', '0.405', '0.406', '0.407', '0.408', '0.409', '0.41', '0.411', '0.412', '0.413', '0.414', '0.415', '0.416', '0.417', '0.418', '0.419', '0.42', '0.421', '0.422', '0.423', '0.424', '0.425', '0.426', '0.427', '0.428', '0.429', '0.43', '0.431', '0.432', '0.433', '0.434', '0.435', '0.436', '0.437', '0.438', '0.439', '0.44', '0.441', '0.442', '0.443', '0.444', '0.445', '0.446', '0.447', '0.448', '0.449', '0.45', '0.451', '0.452', '0.453', '0.454', '0.455', '0.456', '0.457', '0.458', '0.459', '0.46', '0.461', '0.462', '0.463', '0.464', '0.465', '0.466', '0.467', '0.468', '0.469', '0.47', '0.471', '0.472', '0.473', '0.474', '0.475', '0.476', '0.477', '0.478', '0.479', '0.48', '0.481', '0.482', '0.483', '0.484', '0.485', '0.486', '0.487', '0.488', '0.489', '0.49', '0.491', '0.492', '0.493', '0.494', '0.495', '0.496', '0.497', '0.498', '0.499', '0.5', '0.501', '0.502', '0.503', '0.504', '0.505', '0.506', '0.507', '0.508', '0.509', '0.51', '0.511', '0.512', '0.513', '0.514', '0.515', '0.516', '0.517', '0.518', '0.519', '0.52', '0.521', '0.522', '0.523', '0.524', '0.525', '0.526', '0.527', '0.528', '0.529', '0.53', '0.531', '0.532', '0.533', '0.534', '0.535', '0.536', '0.537', '0.538', '0.539', '0.54', '0.541', '0.542', '0.543', '0.544', '0.545', '0.546', '0.547', '0.548', '0.549', '0.55', '0.551', '0.552', '0.553', '0.554', '0.555', '0.556', '0.557', '0.558', '0.559', '0.56', '0.561', '0.562', '0.563', '0.564', '0.565', '0.566', '0.567', '0.568', '0.569', '0.57', '0.571', '0.572', '0.573', '0.574', '0.575', '0.576', '0.577', '0.578', '0.579', '0.58', '0.581', '0.582', '0.583', '0.584', '0.585', '0.586', '0.587', '0.588', '0.589', '0.59', '0.591', '0.592', '0.593', '0.594', '0.595', '0.596', '0.597', '0.598', '0.599', '0.6', '0.601', '0.602', '0.603', '0.604', '0.605', '0.606', '0.607', '0.608', '0.609', '0.61', '0.611', '0.612', '0.613', '0.614', '0.615', '0.616', '0.617', '0.618', '0.619', '0.62', '0.621', '0.622', '0.623', '0.624', '0.625', '0.626', '0.627', '0.628', '0.629', '0.63', '0.631', '0.632', '0.633', '0.634', '0.635', '0.636', '0.637', '0.638', '0.639', '0.64', '0.641', '0.642', '0.643', '0.644', '0.645', '0.646', '0.647', '0.648', '0.649', '0.65', '0.651', '0.652', '0.653', '0.654', '0.655', '0.656', '0.657', '0.658', '0.659', '0.66', '0.661', '0.662', '0.663', '0.664', '0.665', '0.666', '0.667', '0.668', '0.669', '0.67', '0.671', '0.672', '0.673', '0.674', '0.675', '0.676', '0.677', '0.678', '0.679', '0.68', '0.681', '0.682', '0.683', '0.684', '0.685', '0.686', '0.687', '0.688', '0.689', '0.69', '0.691', '0.692', '0.693', '0.694', '0.695', '0.696', '0.697', '0.698', '0.699', '0.7', '0.701', '0.702', '0.703', '0.704', '0.705', '0.706', '0.707', '0.708', '0.709', '0.71', '0.711', '0.712', '0.713', '0.714', '0.715', '0.716', '0.717', '0.718', '0.719', '0.72', '0.721', '0.722', '0.723', '0.724', '0.725', '0.726', '0.727', '0.728', '0.729', '0.73', '0.731', '0.732', '0.733', '0.734', '0.735', '0.736', '0.737', '0.738', '0.739', '0.74', '0.741', '0.742', '0.743', '0.744', '0.745', '0.746', '0.747', '0.748', '0.749', '0.75', '0.751', '0.752', '0.753', '0.754', '0.755', '0.756', '0.757', '0.758', '0.759', '0.76', '0.761', '0.762', '0.763', '0.764', '0.765', '0.766', '0.767', '0.768', '0.769', '0.77', '0.771', '0.772', '0.773', '0.774', '0.775', '0.776', '0.777', '0.778', '0.779', '0.78', '0.781', '0.782', '0.783', '0.784', '0.785', '0.786', '0.787', '0.788', '0.789', '0.79', '0.791', '0.792', '0.793', '0.794', '0.795', '0.796', '0.797', '0.798', '0.799', '0.8', '0.801', '0.802', '0.803', '0.804', '0.805', '0.806', '0.807', '0.808', '0.809', '0.81', '0.811', '0.812', '0.813', '0.814', '0.815', '0.816', '0.817', '0.818', '0.819', '0.82', '0.821', '0.822', '0.823', '0.824', '0.825', '0.826', '0.827', '0.828', '0.829', '0.83', '0.831', '0.832', '0.833', '0.834', '0.835', '0.836', '0.837', '0.838', '0.839', '0.84', '0.841', '0.842', '0.843', '0.844', '0.845', '0.846', '0.847', '0.848', '0.849', '0.85', '0.851', '0.852', '0.853', '0.854', '0.855', '0.856', '0.857', '0.858', '0.859', '0.86', '0.861', '0.862', '0.863', '0.864', '0.865', '0.866', '0.867', '0.868', '0.869', '0.87', '0.871', '0.872', '0.873', '0.874', '0.875', '0.876', '0.877', '0.878', '0.879', '0.88', '0.881', '0.882', '0.883', '0.884', '0.885', '0.886', '0.887', '0.888', '0.889', '0.89', '0.891', '0.892', '0.893', '0.894', '0.895', '0.896', '0.897', '0.898', '0.899', '0.9', '0.901', '0.902', '0.903', '0.904', '0.905', '0.906', '0.907', '0.908', '0.909', '0.91', '0.911', '0.912', '0.913', '0.914', '0.915', '0.916', '0.917', '0.918', '0.919', '0.92', '0.921', '0.922', '0.923', '0.924', '0.925', '0.926', '0.927', '0.928', '0.929', '0.93', '0.931', '0.932', '0.933', '0.934', '0.935', '0.936', '0.937', '0.938', '0.939', '0.94', '0.941', '0.942', '0.943', '0.944', '0.945', '0.946', '0.947', '0.948', '0.949', '0.95', '0.951', '0.952', '0.953', '0.954', '0.955', '0.956', '0.957', '0.958', '0.959', '0.96', '0.961', '0.962', '0.963', '0.964', '0.965', '0.966', '0.967', '0.968', '0.969', '0.97', '0.971', '0.972', '0.973', '0.974', '0.975', '0.976', '0.977', '0.978', '0.979', '0.98', '0.981', '0.982', '0.983', '0.984', '0.985', '0.986', '0.987', '0.988', '0.989', '0.99', '0.991', '0.992', '0.993', '0.994', '0.995', '0.996', '0.997', '0.998', '0.999', '1.0'], 'condition': ['<const> * _in_0+<const> * _in_1+<const> * _in_2+<const> * _in_3 < <const>']}
types: -48,48,5,10;-50,50,5,10;-418,418,5,1000;-836,836,5,1000
consts: {0: ('-4.8', '4.7'), 1: ('-5.0', '4.5'), 2: ('-0.418', '0.417'), 3: ('-0.836', '0.834')}
index: 3
type_: -836,836,5,1000
rng: ['-836', '836', '5', '1000']
start: -836
stop: 836
step: 5
divisor: 1000
consts_: ['-0.836', '-0.831', '-0.826', '-0.821', '-0.816', '-0.811', '-0.806', '-0.801', '-0.796', '-0.791', '-0.786', '-0.781', '-0.776', '-0.771', '-0.766', '-0.761', '-0.756', '-0.751', '-0.746', '-0.741', '-0.736', '-0.731', '-0.726', '-0.721', '-0.716', '-0.711', '-0.706', '-0.701', '-0.696', '-0.691', '-0.686', '-0.681', '-0.676', '-0.671', '-0.666', '-0.661', '-0.656', '-0.651', '-0.646', '-0.641', '-0.636', '-0.631', '-0.626', '-0.621', '-0.616', '-0.611', '-0.606', '-0.601', '-0.596', '-0.591', '-0.586', '-0.581', '-0.576', '-0.571', '-0.566', '-0.561', '-0.556', '-0.551', '-0.546', '-0.541', '-0.536', '-0.531', '-0.526', '-0.521', '-0.516', '-0.511', '-0.506', '-0.501', '-0.496', '-0.491', '-0.486', '-0.481', '-0.476', '-0.471', '-0.466', '-0.461', '-0.456', '-0.451', '-0.446', '-0.441', '-0.436', '-0.431', '-0.426', '-0.421', '-0.416', '-0.411', '-0.406', '-0.401', '-0.396', '-0.391', '-0.386', '-0.381', '-0.376', '-0.371', '-0.366', '-0.361', '-0.356', '-0.351', '-0.346', '-0.341', '-0.336', '-0.331', '-0.326', '-0.321', '-0.316', '-0.311', '-0.306', '-0.301', '-0.296', '-0.291', '-0.286', '-0.281', '-0.276', '-0.271', '-0.266', '-0.261', '-0.256', '-0.251', '-0.246', '-0.241', '-0.236', '-0.231', '-0.226', '-0.221', '-0.216', '-0.211', '-0.206', '-0.201', '-0.196', '-0.191', '-0.186', '-0.181', '-0.176', '-0.171', '-0.166', '-0.161', '-0.156', '-0.151', '-0.146', '-0.141', '-0.136', '-0.131', '-0.126', '-0.121', '-0.116', '-0.111', '-0.106', '-0.101', '-0.096', '-0.091', '-0.086', '-0.081', '-0.076', '-0.071', '-0.066', '-0.061', '-0.056', '-0.051', '-0.046', '-0.041', '-0.036', '-0.031', '-0.026', '-0.021', '-0.016', '-0.011', '-0.006', '-0.001', '0.004', '0.009', '0.014', '0.019', '0.024', '0.029', '0.034', '0.039', '0.044', '0.049', '0.054', '0.059', '0.064', '0.069', '0.074', '0.079', '0.084', '0.089', '0.094', '0.099', '0.104', '0.109', '0.114', '0.119', '0.124', '0.129', '0.134', '0.139', '0.144', '0.149', '0.154', '0.159', '0.164', '0.169', '0.174', '0.179', '0.184', '0.189', '0.194', '0.199', '0.204', '0.209', '0.214', '0.219', '0.224', '0.229', '0.234', '0.239', '0.244', '0.249', '0.254', '0.259', '0.264', '0.269', '0.274', '0.279', '0.284', '0.289', '0.294', '0.299', '0.304', '0.309', '0.314', '0.319', '0.324', '0.329', '0.334', '0.339', '0.344', '0.349', '0.354', '0.359', '0.364', '0.369', '0.374', '0.379', '0.384', '0.389', '0.394', '0.399', '0.404', '0.409', '0.414', '0.419', '0.424', '0.429', '0.434', '0.439', '0.444', '0.449', '0.454', '0.459', '0.464', '0.469', '0.474', '0.479', '0.484', '0.489', '0.494', '0.499', '0.504', '0.509', '0.514', '0.519', '0.524', '0.529', '0.534', '0.539', '0.544', '0.549', '0.554', '0.559', '0.564', '0.569', '0.574', '0.579', '0.584', '0.589', '0.594', '0.599', '0.604', '0.609', '0.614', '0.619', '0.624', '0.629', '0.634', '0.639', '0.644', '0.649', '0.654', '0.659', '0.664', '0.669', '0.674', '0.679', '0.684', '0.689', '0.694', '0.699', '0.704', '0.709', '0.714', '0.719', '0.724', '0.729', '0.734', '0.739', '0.744', '0.749', '0.754', '0.759', '0.764', '0.769', '0.774', '0.779', '0.784', '0.789', '0.794', '0.799', '0.804', '0.809', '0.814', '0.819', '0.824', '0.829', '0.834']
oblique_split: <const> * _in_0+<const> * _in_1+<const> * _in_2+<const> * _in_3
f: <_io.TextIOWrapper name='logs/gym/2022-03-02_22-23-46_yxvbhfqk\\log.txt' mode='a' encoding='cp1252'>
[2022-03-02 22:23:48.031322] New best at generation 0 with fitness (-1000.0,)
[9746, 15384, 9809, 2163, 36107, 11445, 28689, 2404, 16798, 16301, 32865, 6237, 15945, 35955, 28554, 18771, 21790, 6677, 8298, 3406, 14464, 36493, 19585, 6668, 23009, 27321, 28104, 32199, 11388, 10403, 16016, 19549, 29942, 4321, 29731, 7040, 24709, 20167, 24215, 1513, 9419, 28911, 7445, 35756, 35955, 8, 30288, 35525, 9330, 11117, 31892, 32817, 8776, 8726, 38698, 30658, 24932, 1091, 2776, 7906, 2127, 39670, 34522, 4083, 20830, 24959, 27727, 16102, 11089, 24180, 27461, 37652, 30484, 23656, 10868, 28769, 2158, 25192, 11595, 23986, 3580, 23851, 24932, 30769, 9503, 38018, 38157, 5817, 34643, 24020, 21466, 14333, 37229, 22084, 23274, 9621, 3215, 23824, 32876, 9170]
Leaves
{}
[2022-03-02 22:23:48.033312] New best at generation 0 with fitness (9.7,)
[9226, 27156, 9681, 10206, 27297, 7426, 27621, 24309, 6200, 1194, 19913, 22872, 7641, 35223, 8081, 22746, 182, 37627, 32935, 23403, 1099, 970, 38005, 39061, 15112, 9202, 1516, 38719, 38962, 12803, 30868, 5690, 5543, 29883, 25844, 20617, 39355, 31871, 35228, 19721, 17002, 29105, 29149, 10899, 39937, 10769, 6480, 15134, 22507, 25421, 10156, 27, 35786, 8206, 36683, 11126, 706, 4543, 26261, 17697, 17425, 6400, 35940, 18081, 13050, 20205, 27267, 36825, 34523, 24451, 6357, 23868, 14183, 27484, 10082, 14431, 24162, 28279, 33697, 27201, 34553, 32894, 14702, 15525, 30445, 828, 23682, 31701, 37890, 23784, 36235, 19973, 17288, 13667, 36670, 1842, 9619, 18000, 22998, 34990]
Leaves
{'leaf_0': -0.93, -0.02, 0.69, -0.18, 'leaf_1': 0.35, -0.41, 0.09, -0.54}
[2022-03-02 22:23:48.035307] New best at generation 0 with fitness (40.4,)
[23763, 22643, 14359, 35471, 28027, 36471, 9289, 21015, 4761, 3281, 31986, 3004, 39436, 28815, 31148, 32497, 28536, 21158, 20930, 4501, 16408, 38541, 34759, 29236, 13082, 3034, 20030, 9471, 18969, 29443, 28003, 31686, 17880, 34991, 16643, 35259, 3436, 28754, 31748, 28697, 2762, 38064, 18521, 6691, 30024, 16123, 8774, 37851, 18670, 12970, 11648, 3837, 10556, 37018, 31928, 37202, 12240, 27665, 35063, 10609, 28593, 33398, 39767, 6431, 26794, 17707, 32643, 7434, 31979, 25219, 24845, 33056, 29086, 519, 6834, 15441, 21249, 28931, 20162, 16327, 31030, 7396, 14110, 39081, 13266, 10144, 394, 31388, 8344, 31223, 34952, 23177, 7450, 11305, 8376, 7289, 26667, 14198, 27754, 8233]
Leaves
{'leaf_0': -0.93, -0.02, 0.69, -0.18, 'leaf_1': 0.43, -0.41, 0.09, -0.54, 'leaf_2': -0.51, 0.95, 0.29, -0.96}
[2022-03-02 22:23:50.748186] New best at generation 2 with fitness (42.6,)
[39398, 22896, 15168, 26823, 21640, 13417, 1210, 3236, 2651, 1964, 28118, 33704, 7410, 3327, 508, 21180, 9681, 20867, 33736, 17320, 3926, 949, 25931, 4642, 3682, 18145, 23872, 10449, 4114, 1931, 3479, 7448, 11801, 2876, 22572, 8210, 24903, 12495, 986, 7270, 24273, 22405, 39213, 37041, 37057, 25924, 39170, 827, 17161, 28286, 11339, 36813, 4280, 400, 26302, 35278, 36349, 25263, 3445, 1693, 13313, 584, 1692, 12875, 34783, 931, 18417, 3117, 633, 14817, 32063, 34511, 32040, 21382, 922, 837, 16076, 2882, 38149, 28869, 8410, 30750, 8228, 34186, 28266, 30453, 25535, 6487, 6658, 3227, 32542, 3656, 21330, 1756, 23273, 19869, 1058, 3586, 13163, 26964]
Leaves
{'leaf_0': 0.18, 0.93, -0.29, -0.03, 'leaf_1': 0.19, 0.86, -0.82, -0.58, 'leaf_2': 0.73, 0.83, -0.88, -0.58, 'leaf_3': 0.35, -0.78, -0.59, -0.17, 'leaf_4': 0.31, -0.14, -0.35, -0.51, 'leaf_5': 0.98, 0.22, -0.43, -0.55, 'leaf_6': 0.60, 0.02, -0.98, 0.56}
[2022-03-02 22:23:52.363760] New best at generation 3 with fitness (57.666666666666664,)
[37228, 36321, 37589, 24192, 19656, 29428, 1655, 30666, 18278, 37806, 4909, 1945, 36122, 2125, 25320, 15798, 25654, 468, 35752, 11257, 27938, 5996, 28893, 3376, 28131, 22171, 29698, 7998, 34769, 38970, 9849, 2045, 31915, 36388, 1100, 23740, 27745, 25423, 34004, 29339, 19111, 2981, 32878, 709, 29478, 7199, 16367, 36548, 198, 4568, 10343, 11680, 23551, 30325, 1572, 20127, 25782, 3660, 6517, 13682, 9752, 30041, 3961, 31751, 1578, 3856, 31487, 35940, 233, 20768, 39250, 137, 34575, 18341, 33881, 29534, 15598, 9077, 257, 5270, 743, 19685, 5917, 3698, 23432, 3742, 975, 33336, 8433, 17745, 38488, 1786, 26134, 21971, 37163, 28207, 1678, 3570, 7961, 32557]
Leaves
{'leaf_0': 0.64, 0.00, -0.18, 0.42, 'leaf_1': -0.64, 0.86, 0.18, -0.44}
[2022-03-02 22:24:01.379132] New best at generation 8 with fitness (106.22222222222223,)
[698, 1568, 529, 2145, 3128, 8799, 6069, 17070, 20535, 2363, 1554, 2602, 9803, 837, 9469, 3438, 15554, 1551, 1505, 13626, 16838, 20148, 32079, 13043, 3840, 17323, 2217, 1178, 3940, 37874, 8077, 2408, 547, 1882, 28239, 1287, 1825, 8202, 812, 2557, 21388, 2444, 1997, 31385, 13753, 15503, 2469, 23581, 39088, 37114, 2612, 35364, 23223, 7030, 3561, 34608, 1458, 24472, 29662, 5279, 2340, 368, 3446, 21721, 23058, 1813, 37351, 31339, 1603, 21344, 17295, 3584, 6434, 23327, 981, 11405, 8914, 37123, 2813, 36662, 20942, 11720, 10619, 5543, 29552, 6445, 1256, 17275, 2532, 1283, 35187, 25400, 27580, 2414, 30867, 6855, 80, 15307, 31723, 6336]
Leaves
{'leaf_0': 0.18, 1.12, -0.29, -0.03, 'leaf_1': 0.19, 0.82, -0.82, -0.58, 'leaf_2': 0.73, 0.83, -0.88, -0.58, 'leaf_3': 0.18, -0.78, -0.59, -0.17, 'leaf_4': 0.31, -0.14, -0.35, -0.51, 'leaf_5': 0.98, 0.22, -0.43, -0.55, 'leaf_6': 0.60, 0.02, -0.98, 0.56, 'leaf_7': 0.81, -0.33, -0.68, -0.44, 'leaf_8': 0.83, 0.13, 0.46, 0.08}
[2022-03-02 22:24:32.381100] New best at generation 16 with fitness (115.0,)
[201, 12048, 227, 10941, 27599, 6733, 34124, 3040, 29297, 1019, 24502, 6188, 33200, 9401, 4877, 20330, 34451, 3096, 3026, 715, 35212, 36697, 2978, 13219, 38052, 2512, 3908, 1002, 3797, 1, 17008, 1961, 17888, 872, 21048, 27378, 3826, 16885, 1413, 21658, 2549, 36366, 1793, 36149, 14145, 1212, 35502, 1644, 9954, 23641, 2707, 7954, 558, 1798, 3280, 9431, 3407, 3124, 1297, 12949, 5043, 103, 1649, 13417, 39728, 28181, 28430, 550, 21918, 2670, 137, 3596, 25260, 3910, 3412, 23175, 2938, 1312, 3172, 34809, 607, 21971, 833, 1317, 37814, 106, 33984, 16078, 9301, 21438, 2071, 25341, 36726, 2426, 11832, 4694, 21349, 5557, 23320, 29805]
Leaves
{'leaf_0': -0.93, -0.02, 0.69, -0.18, 'leaf_1': 0.26, -0.42, 0.09, -0.54, 'leaf_2': -0.51, 1.02, 0.29, -0.96, 'leaf_3': 1.09, 0.47, 0.44, -0.18}
[2022-03-02 22:24:47.607293] New best at generation 23 with fitness (205.0,)
[201, 400, 1787, 10941, 27599, 6733, 3805, 3040, 29297, 2202, 24502, 1034, 33200, 9401, 3538, 20330, 34451, 3096, 3026, 715, 35212, 2655, 2978, 13219, 38052, 2512, 2382, 1002, 3994, 1, 17008, 1961, 1727, 1592, 2078, 1220, 3826, 16885, 2710, 21658, 2549, 715, 1793, 36149, 14145, 1212, 762, 1644, 9954, 23641, 2707, 3214, 558, 1798, 3280, 9431, 3407, 3124, 1297, 12949, 5043, 103, 1649, 13417, 39728, 28181, 28430, 550, 21918, 2670, 137, 3596, 25260, 3910, 1860, 23175, 2938, 1312, 3172, 34809, 607, 21971, 833, 1317, 37814, 106, 33984, 16078, 9301, 21438, 412, 25341, 36726, 2426, 11832, 4694, 2976, 5557, 23320, 29805]
Leaves
{'leaf_0': -0.23, -0.95, -0.95, 0.85, 'leaf_1': 0.14, -0.67, -0.87, 0.69, 'leaf_2': 0.51, -0.01, 0.10, -0.23, 'leaf_3': -0.60, 0.56, -0.04, -0.80}
[2022-03-02 22:24:58.997097] New best at generation 28 with fitness (222.0,)
[1141, 34682, 5779, 1965, 2929, 10493, 18179, 2982, 1323, 2453, 9025, 2382, 1036, 963, 3636, 28877, 3325, 2368, 24209, 5483, 2168, 852, 7199, 28158, 18888, 21668, 8654, 4358, 38237, 1230, 22787, 8983, 508, 1267, 10748, 12635, 29104, 2392, 3258, 10456, 1247, 179, 30827, 2887, 32238, 4811, 26184, 32840, 21035, 3654, 29860, 15812, 17197, 30078, 1420, 510, 479, 2892, 3715, 5020, 18992, 3475, 1832, 30574, 3789, 3332, 1952, 2122, 3801, 2604, 2412, 470, 236, 29018, 2736, 2750, 692, 3539, 3841, 19252, 1796, 12858, 32595, 5397, 3818, 3429, 2355, 37604, 650, 21126, 22904, 3028, 11103, 2666, 2674, 35183, 2180, 2402, 3763, 655]
Leaves
{'leaf_0': 0.18, 0.93, -0.29, -0.03, 'leaf_1': 0.19, 0.82, -0.82, -0.58, 'leaf_2': 0.73, 0.88, -0.88, -0.58, 'leaf_3': 0.35, -0.77, -0.59, -0.17}
[2022-03-02 22:25:03.740592] New best at generation 30 with fitness (238.0,)
[3245, 424, 529, 2989, 645, 8799, 6069, 1072, 20535, 2363, 1554, 2602, 9803, 837, 9469, 1319, 2, 1551, 1671, 13626, 179, 20148, 1818, 13043, 3840, 17323, 3749, 1178, 3940, 37874, 8077, 2408, 547, 1882, 28239, 1287, 1825, 518, 812, 1718, 2729, 1374, 1997, 31385, 13753, 15503, 2469, 23581, 39088, 37114, 3520, 3786, 23223, 7030, 3561, 34608, 2972, 265, 29662, 5279, 2340, 3700, 3870, 21721, 23058, 1813, 37351, 31339, 1603, 550, 17295, 3266, 103, 23327, 981, 11405, 8914, 993, 953, 36662, 20942, 11720, 10619, 5543, 1427, 3337, 1256, 17275, 2532, 1283, 35187, 2494, 656, 2414, 30867, 1824, 2076, 3875, 31723, 6336]
Leaves
{'leaf_0': 0.18, 0.96, -0.29, -0.03, 'leaf_1': 0.19, 0.82, -0.82, -0.58, 'leaf_2': 0.73, 0.83, -0.88, -0.58, 'leaf_3': 0.18, -0.78, -0.59, -0.17, 'leaf_4': 0.31, -0.14, -0.35, -0.51, 'leaf_5': 0.98, 0.22, -0.43, -0.55, 'leaf_6': 0.61, 0.02, -0.98, 0.56, 'leaf_7': 0.24, -0.33, -0.68, -0.44, 'leaf_8': 0.83, 0.13, 0.46, 0.08, 'leaf_9': -0.67, 0.35, -0.62, 0.08}
[2022-03-02 22:25:42.073371] New best at generation 48 with fitness (243.0,)
[3244, 424, 3284, 2989, 645, 8799, 6069, 1072, 20535, 2363, 1554, 2602, 9803, 3509, 1161, 1319, 2, 1551, 1671, 13626, 179, 20148, 313, 13043, 3840, 2713, 3749, 1178, 3940, 37874, 8077, 2408, 547, 1882, 28239, 2747, 1825, 518, 492, 1718, 2729, 1363, 2443, 922, 13753, 15503, 2469, 1355, 39088, 37114, 3320, 3786, 1816, 7030, 2685, 34608, 3082, 3340, 29662, 5279, 3881, 3700, 3870, 21721, 127, 3769, 159, 31339, 1603, 550, 3831, 3266, 3939, 23327, 981, 11405, 8914, 993, 953, 36662, 20942, 11720, 10619, 5543, 1427, 3337, 1256, 17275, 2532, 1283, 35187, 2494, 656, 2414, 30867, 1824, 2076, 2216, 31723, 6336]
Leaves
{'leaf_0': 0.19, 1.17, -0.29, -0.03, 'leaf_1': 0.19, 0.82, -0.82, -0.58, 'leaf_2': 0.74, 0.86, -0.88, -0.58, 'leaf_3': 0.18, -0.78, -0.59, -0.17, 'leaf_4': 0.31, -0.14, -0.35, -0.51, 'leaf_5': 0.99, 0.23, -0.43, -0.55, 'leaf_6': 1.00, 0.02, -0.98, 0.56, 'leaf_7': 0.05, -0.33, -0.68, -0.44, 'leaf_8': 0.83, 0.13, 0.46, 0.08, 'leaf_9': -0.67, 0.35, -0.62, 0.08}

Fitness history:
gen	nevals	avg     	std    	min  	max    
0  	200   	-741.92 	441.14 	-1000	40.4   
1  	200   	-509.44 	505.52 	-1000	40.4   
2  	200   	-286.8  	461.373	-1000	42.6   
3  	200   	-174.841	393.203	-1000	57.6667
4  	200   	-72.7048	282.76 	-1000	57.6667
5  	200   	-36.5737	221.209	-1000	57.6667
6  	200   	-14.4822	173.63 	-1000	57.6667
7  	200   	7.00748 	101.782	-1000	57.6667
8  	200   	19.4483 	13.2889	9.6  	106.222
9  	200   	20.9846 	14.1007	9.6  	106.222
10 	200   	22.674  	15.1206	9.6  	106.222
11 	200   	25.5776 	16.367 	9.6  	106.222
12 	200   	27.3738 	17.5994	9.6  	106.222
13 	200   	28.5216 	17.5392	9.6  	106.222
14 	200   	30.0113 	17.6999	9.6  	106.222
15 	200   	31.8897 	18.0015	9.6  	106.222
16 	200   	33.6726 	19.134 	9.6  	115    
17 	200   	34.968  	19.7566	9.7  	115    
18 	200   	35.7908 	19.5927	9.7  	115    
19 	200   	38.8573 	19.5963	9.7  	115    
20 	200   	40.0736 	19.7088	9.7  	115    
21 	200   	42.2433 	20.5003	9.7  	115    
22 	200   	44.2509 	21.6237	9.7  	115    
23 	200   	47.5455 	25.5006	9.7  	205    
24 	200   	51.0237 	26.443 	9.7  	205    
25 	200   	54.9693 	26.4359	10   	205    
26 	200   	56.3989 	26.4202	10   	205    
27 	200   	58.2663 	26.8603	10   	205    
28 	200   	62.9362 	30.1347	12   	222    
29 	200   	66.1257 	31.6911	12   	222    
30 	200   	69.9646 	36.3961	12   	238    
31 	200   	74.1085 	38.57  	12   	238    
32 	200   	79.1707 	42.274 	12   	238    
33 	200   	82.1844 	43.2937	17.3 	238    
34 	200   	85.8849 	45.0686	17.3 	238    
35 	200   	90.4177 	45.7494	17.3 	238    
36 	200   	94.6224 	46.1183	17.3 	238    
37 	200   	100.315 	46.993 	17.3 	238    
38 	200   	106.339 	49.3486	17.3 	238    
39 	200   	110.325 	48.9272	17.3 	238    
40 	200   	115.227 	49.342 	17.3 	238    
41 	200   	120.523 	49.116 	17.3 	238    
42 	200   	126.323 	51.1317	17.3 	238    
43 	200   	135.929 	52.5627	17.3 	238    
44 	200   	140.797 	51.9584	17.3 	238    
45 	200   	146.805 	50.6378	17.3 	238    
46 	200   	151.033 	49.6292	30   	238    
47 	200   	155.538 	51.0966	40.4 	238    
48 	200   	161.388 	51.6536	40.4 	243    
49 	200   	164.469 	51.5299	40.4 	243    
50 	200   	166.802 	52.0715	40.4 	243    

HOF-Individual:
[3244, 424, 3284, 2989, 645, 8799, 6069, 1072, 20535, 2363, 1554, 2602, 9803, 3509, 1161, 1319, 2, 1551, 1671, 13626, 179, 20148, 313, 13043, 3840, 2713, 3749, 1178, 3940, 37874, 8077, 2408, 547, 1882, 28239, 2747, 1825, 518, 492, 1718, 2729, 1363, 2443, 922, 13753, 15503, 2469, 1355, 39088, 37114, 3320, 3786, 1816, 7030, 2685, 34608, 3082, 3340, 29662, 5279, 3881, 3700, 3870, 21721, 127, 3769, 159, 31339, 1603, 550, 3831, 3266, 3939, 23327, 981, 11405, 8914, 993, 953, 36662, 20942, 11720, 10619, 5543, 1427, 3337, 1256, 17275, 2532, 1283, 35187, 2494, 656, 2414, 30867, 1824, 2076, 2216, 31723, 6336]

Phenotype:
if -0.012 * _in_0+-0.355 * _in_1+-0.205 * _in_2+-0.934 * _in_3 < 0.072:
    if -0.399 * _in_0+0.799 * _in_1+0.508 * _in_2+0.161 * _in_3 < 0.319:
        out=1
        
    else:
        if -0.821 * _in_0+-0.862 * _in_1+-0.687 * _in_2+0.037 * _in_3 < 0.839:
            if 0.939 * _in_0+0.856 * _in_1+-0.927 * _in_2+-0.593 * _in_3 < -0.453:
                out=1
                
            else:
                if -0.482 * _in_0+-0.508 * _in_1+0.718 * _in_2+-0.272 * _in_3 < 0.363:
                    if 0.496 * _in_0+-0.532 * _in_1+0.355 * _in_2+0.069 * _in_3 < 0.096:
                        out=1
                        
                    else:
                        out=0
                        
                    
                else:
                    out=0
                    
                
            
        else:
            out=0
            
        
    
else:
    if 0.339 * _in_0+0.648 * _in_1+0.277 * _in_2+0.88 * _in_3 < 0.699:
        out=0
        
    else:
        if -0.841 * _in_0+0.324 * _in_1+0.603 * _in_2+-0.45 * _in_3 < 0.83:
            out=0
            
        else:
            if 0.4 * _in_0+-0.09 * _in_1+-0.007 * _in_2+-0.047 * _in_3 < -0.356:
                out=0
                
            else:
                out=1
                
            
        
    
best_fitness: 243.0
[2022-03-02 22:25:45.734243]